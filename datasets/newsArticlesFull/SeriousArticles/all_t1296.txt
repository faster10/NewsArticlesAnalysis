Stephen Hawking thinks these 3 things could destroy humanity
Stephen Hawking may be most famous for his work on black holes andgravitational singularities, but the world-renowned physicist has alsobecome known for his outspoken ideas about things that could destroyhuman civilization.Hawking suffers from a motor neuron diseasesimilar to amyotrophic lateral sclerosis, or ALS, which left himparalyzed and unable to speak without a voice synthesizer. But thathasn't stopped the University of Cambridge professor from makingproclamations about the wide range of dangers humanity faces -- includingourselves.Here are a few things Hawking has said could bring about the demise of human civilization. [End of the World? Top Doomsday Fears]Artificial intelligenceHawking is part of a small but growing group of scientists who have expressed concerns about "strong" artificial intelligence (AI) -- intelligence that could equal or exceed that of a human."The development of full artificial intelligence could spell the end ofthe human race," Hawking told the BBC in December 2014. The statementwas in response to a question about a new AI voice-synthesizing systemthat Hawking has been using.Hawking's warnings echo those of billionaire entrepreneur Elon Musk,CEO of SpaceX and Tesla Motors, who has called AI humanity's "biggest existential threat."Last month, Hawking, Musk and dozens of other scientific bigwigs signedan open letterdescribing the risks, as well as the benefits, of AI."Because of the great potential of AI, it is important to research howto reap its benefits while avoiding potential pitfalls," the scientists wrote in the letter,which was published online Jan. 11 by the Future of Life Institute, avolunteer organization that aims to mitigate existential threats tohumanity.But many AI researchers say humanity is nowhere near being able to develop strong AI."We are decades away from any technology we need to worry about," DemisHassabis, an artificial intelligence researcher at Google DeepMind,told reporters this week at a news conference about a new AI program hedeveloped that can teach itself to play computer games. Still, "It'sgood to start the conversation now," he added.Human aggressionIf our machines don't kill us, we might kill ourselves. Hawking now believes that human aggression might destroy civilization.The physicist was giving a tour of the London Science Museum to AdaezeUyanwah, a 24-year-old teacher from California who won a contest fromVisitLondon.com. When Uyanwah asked, "What human shortcomings would youmost like to alter?" Hawking responded:"The human failing I would most like to correct is aggression. It mayhave had survival advantage in caveman days, to get more food, territoryor partner with whom to reproduce, but now it threatens to destroy usall," The Independent reported.For example, a major nuclear war would likely end civilization, andcould wipe out the human race, Hawking added. When asked which humanquality he would most like to magnify, Hawking chose empathy, because"it brings us together in a peaceful, loving state."Hawking thinks space exploration will be important to ensuring thesurvival of humanity. "I believe that the long-term future of the humanrace must be space, and that it represents an important life insurancefor our future survival, as it could prevent the disappearance ofhumanity by colonizing other planets," Cambridge News reported.Alien lifeBut Hawking had made ominous warnings even before these recent ones.Back in 2010, Hawking said that, if intelligent alien life exists, it may not be that friendly toward humans."If aliens ever visit us, I think the outcome would be much as whenChristopher Columbus first landed in America, which didn't turn out verywell for the Native Americans," Hawking said during an episode of "Intothe Universe with Stephen Hawking," a show hosted by the DiscoveryChannel, reported The Times, a U.K.-based newspaper.Advanced alien civilizations might become nomads, looking to conquerand colonize whatever planets they could reach, Hawking said. "If so, itmakes sense for them to exploit each new planet for material to buildmore spaceships so they could move on. Who knows what the limits wouldbe?"From the threat of nefarious AI, to advanced aliens, to hostile humans, Hawking's outlook for humanity is looking pretty grim.